{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats\n",
    "import sys\n",
    "sys.path.append('./models/')\n",
    "from SIR import derive, differenciate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing mobility from the csv file\n",
    "df_mobility=pd.read_csv('mobility.csv')\n",
    "df_mobility.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "mobility=np.array(df_mobility['mobility'])\n",
    "\n",
    "df = pd.read_csv('deaths_and_infections.csv')\n",
    "\n",
    "# remove a columns from a df: \n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "new_deaths=np.array(df['new_deaths'])\n",
    "n_infected=np.array(df['n_infected'])\n",
    "death_cumul=np.array([sum(new_deaths[:i]) for i in range(len(new_deaths))])\n",
    "dates_of_pandemic=np.arange(len(new_deaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[ new_deaths, n_infected, mobility ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Multi_Dimensional_Model: \n",
    "    def __init__(self) :\n",
    "        self.trained=False\n",
    "    def reinitialize(self): \n",
    "        self.trained=False\n",
    "        self.data=None\n",
    "        self.train_dates=None\n",
    "        self.model=None\n",
    "    def train(self, train_dates, data):\n",
    "        self.train_dates=train_dates\n",
    "        self.data=data # to be implemented in the child class\n",
    "    def predict(self, reach, alphas):\n",
    "        pass # to be implemented in the child class \n",
    "\n",
    "    def plot(self, reach, alpha, title=None): \n",
    "        assert self.trained, 'The model has not been trained yet'\n",
    "        prediction, intervals = self.predict(reach, alpha)\n",
    "        ci_low=[max(0, intervals[0][i]) for i in range(len(intervals[0]))]\n",
    "        ci_high=intervals[1]\n",
    "        plt.plot([i for i in range(len(self.data))], self.data, label='real data')\n",
    "        plt.plot([i for i in range(len(self.data), len(self.data) + reach)] , prediction, label='forecast ')\n",
    "        plt.fill_between([i for i in range(len(self.data), len(self.data) + reach)], ci_low, ci_high, color='black', alpha=.3, label='confidence interval at ' + str(round((1-alpha)*100)) + '%')\n",
    "        plt.legend()\n",
    "        plt.axvline(len(self.data), linestyle='--')\n",
    "        plt.xlim(0,len(self.data)+reach)\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def grad_theta_h_m(theta, x): \n",
    "    a0=theta[0]\n",
    "    a1=theta[1]\n",
    "    a2=theta[2]\n",
    "    b0=theta[3]\n",
    "    b1=theta[4]\n",
    "    b2=theta[5]\n",
    "    c=theta[6]\n",
    "    grad=np.zeros(7)\n",
    "    grad[0]=np.exp(b0*x[0])\n",
    "    grad[1]=np.exp(b1*x[0])\n",
    "    grad[2]=np.exp(b2*x[0])\n",
    "    grad[3]=a0*x[0]*np.exp(b0*x[0])\n",
    "    grad[4]=a1*x[0]*np.exp(b1*x[0])\n",
    "    grad[5]=a2*x[0]*np.exp(b2*x[0])\n",
    "    grad[6]=1\n",
    "    return grad \n",
    "\n",
    "def exponential_function_m(X, a0, a1, a2, b0, b1, b2, c): \n",
    "    i, n_infected, mobility = X\n",
    "\n",
    "    return a0*np.exp(b0*i ) + a1*np.exp(b1*n_infected ) + a2*np.exp(b2*mobility ) + c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiDimensionalExponentialRegression(Multi_Dimensional_Model): \n",
    "    def train(self, train_dates, data):\n",
    "        self.data=data\n",
    "        train_dates=np.array(train_dates)\n",
    "        self.train_dates=train_dates\n",
    "        min=len(data[0])-30\n",
    "        max=len(data[0])-1\n",
    "        interval=[i for i in range(min,max)]\n",
    "        self.interval=interval\n",
    "        self.p, self.cov =curve_fit(exponential_function_m, (train_dates[interval], data[1][interval], data[2][interval]),data[0][interval],  p0=[ 1,1, 1, 1,1, 1, 1], maxfev = 1000000)\n",
    "        self.trained=True\n",
    "\n",
    "\n",
    "    def predict(self, reach, alpha, method='covariance'):\n",
    "        assert self.trained, 'The model has not been trained yet'\n",
    "        a0=self.p[0]\n",
    "        a1=self.p[1]\n",
    "        a2=self.p[2]\n",
    "        b0=self.p[3]\n",
    "        b1=self.p[4]\n",
    "        b2=self.p[5]\n",
    "        c=self.p[6]\n",
    "        window_prediction=np.array([i for i in range(len(self.train_dates), len(self.train_dates) + reach )])\n",
    "        self.window_prediction=window_prediction\n",
    "      \n",
    "        prediction=exponential_function_m(window_prediction, ,a0, a1, a2,b0, b1, b2,c)\n",
    "        self.prediction=prediction\n",
    "\n",
    "        perr = np.sqrt(np.diag(self.cov))\n",
    "        self.perr=perr     \n",
    "        ci_low=[]\n",
    "        ci_high=[]\n",
    "        grads= []\n",
    "        vars=[]\n",
    "        for i in range(len(prediction)):\n",
    "            index = self.window_prediction[i] \n",
    "            grad=grad_theta_h_m(self.p, index)\n",
    "            grads.append(grad)\n",
    "            varhtheta=self.cov \n",
    "            varprediction=np.matmul(np.matmul(grad.transpose(), varhtheta), grad)\n",
    "            vars.append(varprediction)\n",
    "            down = scipy.stats.norm.ppf(alpha/2, loc=prediction[i], scale=np.sqrt(varprediction))\n",
    "            ci_low.append(down)\n",
    "            up = scipy.stats.norm.ppf(1-(alpha/2), loc=prediction[i], scale=np.sqrt(varprediction))\n",
    "            ci_high.append(up)\n",
    "        self.ci_low=ci_low\n",
    "        self.ci_high=ci_high\n",
    "        self.grads=grads\n",
    "        self.vars=vars\n",
    "        return prediction, [ci_low, ci_high]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[data[0][:30], data[1][:30], data[2][:30]]\n",
    "dates_of_pandemic_train=dates_of_pandemic[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_21764\\3141172186.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  return a0*np.exp(b0*i ) + a1*np.exp(b1*n_infected ) + a2*np.exp(b2*mobility ) + c\n"
     ]
    }
   ],
   "source": [
    "myexp=MultiDimensionalExponentialRegression()\n",
    "myexp.train(dates_of_pandemic_train, data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_sir_m(x0, a, b , gamma,d, mobility , dt):\n",
    "    t=len(mobility)\n",
    "    x=x0\n",
    "    S=[x[0]]\n",
    "    I=[x[1]]\n",
    "    R=[x[2]]\n",
    "    D=[x[3]] # deads \n",
    "    n_iter=int(t/dt)\n",
    "    N=sum(x0)\n",
    "    for i in range(n_iter):\n",
    "        todays_mobility=mobility[int(i*dt)]\n",
    "        beta=a*todays_mobility+b\n",
    "        x=x+dt*derive(x, beta, N, gamma, d)\n",
    "        S.append(x[0])\n",
    "        I.append(x[1])\n",
    "        R.append(x[2])\n",
    "        D.append(x[3])\n",
    "    s_final=[]\n",
    "    i_final=[]\n",
    "    r_final=[]\n",
    "    d_final=[]\n",
    "    time=np.linspace(0, t, int(t/dt) )\n",
    "    for i in range(len(time)-1):\n",
    "        if abs(time[i]-int(time[i]))<dt: \n",
    "            s_final.append(S[i])\n",
    "            i_final.append(I[i])\n",
    "            r_final.append(R[i])\n",
    "            d_final.append(D[i])\n",
    "    return s_final, i_final, r_final, d_final\n",
    "\n",
    "def sir_for_optim_m( x, a, b ,d, mobility): # returns firts the number of deaths and then the number of total infected\n",
    "    \n",
    "    s_0=1000000 -1\n",
    "    i_0=1\n",
    "    r_0=0\n",
    "    d_0=0\n",
    "    x0=np.array([s_0, i_0, r_0, d_0])\n",
    "    dt=0.001\n",
    "\n",
    "    S, I, R, D = run_sir_m(x0, a, b , 0.2,d, mobility ,   dt)\n",
    "    zer=np.array([0])\n",
    "    d_arr=np.array(D)\n",
    "    return np.concatenate((differenciate(np.concatenate((zer,d_arr))), I))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def f(interval, alpha, beta): \n",
    "    return np.concatenate((np.array(alpha*interval-x_obj) , np.array(beta*interval**2-y_obj)))\n",
    "\n",
    "x_obj = np.array([2, 4, 6, 8, 10])\n",
    "y_obj = np.array([1, 12, 27, 48, 75])\n",
    "interval = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "popt, pcov = curve_fit(f, interval, np.concatenate((x_obj, y_obj)), p0=[2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Multi_SIRD_model(Model): \n",
    "    s_0=1000000 -1\n",
    "    i_0=1\n",
    "    r_0=0\n",
    "    d_0=0\n",
    "    dt=0.001\n",
    "    def train(self, train_dates, data):\n",
    "        self.data=data\n",
    "        self.train_dates=train_dates\n",
    "        curve = lambda a, b, d : sir_for_optim_m(np.array([i for i in range(len(train_dates))]), a, b, d, data[2])\n",
    "        p,cov= curve_fit(curve, self.train_dates,data, p0=[ 1, 1 , 5.523e-04],  bounds=([-np.inf, -np.inf, 0], [np.inf,np.inf, np.inf]))\n",
    "        self.a=p[0]\n",
    "        self.b=p[1]\n",
    "        self.d=p[2]\n",
    "        self.gamma=0.2\n",
    "        self.cov=cov\n",
    "        self.trained= True\n",
    "    def predict(self, reach, alpha, method='covariance'):\n",
    "        S,I,R,D=run_sir([s_0, i_0, r_0, d_0], self.beta, self.gamma, self.d , len(self.train_dates), 0.001)\n",
    "        self.S=S\n",
    "        self.I=I\n",
    "        self.R=R\n",
    "        self.D=D\n",
    "        assert self.trained, 'The model has not been trained yet'\n",
    "        deads=sir_for_optim(np.array([i for i in range(len(self.train_dates)+reach)]), self.beta, self.gamma,self.d)\n",
    "        self.prediction =  deads[-reach:]\n",
    "        prediction=self.prediction\n",
    "        if method == 'covariance': \n",
    "            perr = np.sqrt(np.diag(self.cov)) # Idea from: https://github.com/philipgerlee/Predicting-regional-COVID-19-hospital-admissions-in-Sweden-using-mobility-data.\n",
    "        self.perr=perr\n",
    "        intervals=[np.array(prediction)]\n",
    "        beta_sampled=[]\n",
    "        d_sampled=[]\n",
    "        for i in range(100):\n",
    "            a=np.random.multivariate_normal([self.beta,self.d], self.cov, 1)[0] # not sampling along gamma because gamma is centered on zero so when we sample along gamma and we resample when the value of one of the component is over zero, we elminiate half of the values and have very bad predictions\n",
    "            while not (a>0).all(): \n",
    "                a=np.random.multivariate_normal([self.beta,self.d], self.cov, 1)[0]\n",
    "            beta_sampled.append(a[0])\n",
    "            d_sampled.append(a[1])\n",
    "            beta_r=a[0]\n",
    "            d_r=a[1]\n",
    "            _, _, _, deads_sampled = run_sir([self.S[-1], self.I[-1], self.R[-1], self.D[-1]], beta_r, self.gamma, d_r, reach+1, 0.001)\n",
    "            d_arr=np.array(differenciate(np.array(deads_sampled)))\n",
    "            prediction_sampled=d_arr\n",
    "            intervals.append(prediction_sampled)\n",
    "        self.beta_sampled=beta_sampled\n",
    "        self.d_sampled=d_sampled\n",
    "        intervals=np.array(intervals).transpose()\n",
    "        self.intervals=intervals\n",
    "        ci_low=np.array([np.quantile(intervals[i], alpha/2) for i in range(reach)])\n",
    "        ci_high=np.array([np.quantile(intervals[i],1-alpha/2) for i in range(reach)])\n",
    "        delta_method=True\n",
    "        if delta_method: \n",
    "            print('delta-method')\n",
    "            ci_low=[]\n",
    "            ci_high=[]\n",
    "            grad=grad_theta_h_theta([self.S[-1], self.I[-1], self.R[-1], self.D[-1]], [self.beta, self.d], reach) # size 3 x reach\n",
    "            cov=self.cov\n",
    "            vars=(grad.transpose() @ cov @ grad).transpose()[0]\n",
    "            assert(len(vars)==reach, str(len(vars)) + 'different from ' + str(reach))\n",
    "            for i in range(len(vars)): \n",
    "                down = scipy.stats.norm.ppf(alpha/2, loc=self.prediction[i], scale=np.sqrt(vars[i]))\n",
    "                ci_low.append(down)\n",
    "                up = scipy.stats.norm.ppf(1-(alpha/2), loc=self.prediction[i], scale=np.sqrt(vars[i]))\n",
    "                ci_high.append(up)\n",
    "            self.ci_low=ci_low\n",
    "            self.ci_high=ci_high\n",
    "        else: \n",
    "            print('sampling parameters')\n",
    "        return prediction, [ci_low, ci_high]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_qcm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
